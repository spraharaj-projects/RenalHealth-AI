{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\supre\\\\PycharmProjects\\\\RenalHealth-AI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_state_dict_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_agumentation: bool\n",
    "    params_image_size: List[int]\n",
    "    params_learning_rate: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_classifier.constants import *\n",
    "from cnn_classifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path: Path = CONFIG_FILE_PATH,\n",
    "        params_file_path: Path = PARAMS_FILE_PATH,\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        updated_base_model_path = self.config.prepare_base_model.updated_base_model_path\n",
    "        unzip_dir = self.config.data_ingestion.unzip_dir\n",
    "        params = self.params\n",
    "        training_data = os.path.join(\n",
    "            unzip_dir,\n",
    "            \"kidney-dataset\",\n",
    "        )\n",
    "        create_directories([training.root_dir])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_state_dict_path=Path(training.trained_model_state_dict_path),\n",
    "            updated_base_model_path=Path(updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_agumentation=params.AGUMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            params_learning_rate=params.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from torch import (\n",
    "    device as torch_device,\n",
    "    cuda as torch_cuda,\n",
    "    load as torch_load,\n",
    "    save as torch_save,\n",
    "    max as torch_max,\n",
    "    randint as torch_randint,\n",
    "    int64 as torch_int64,\n",
    "    nn,\n",
    "    no_grad,\n",
    ")\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.optim import SGD\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from cnn_classifier import logger\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.device = torch_device(\n",
    "            \"cuda\" if torch_cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = torch_load(self.config.updated_base_model_path)\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        train_transform = v2.Compose([\n",
    "            v2.Resize(self.config.params_image_size[:-1]),\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomRotation(40),\n",
    "            v2.RandomAffine(\n",
    "                degrees=0,\n",
    "                translate=(0.2, 0),\n",
    "                shear=0.2,\n",
    "                scale=(0.8, 1.2),\n",
    "            ),\n",
    "            v2.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.2,\n",
    "                hue=0.2\n",
    "            ),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        valid_transform = v2.Compose([\n",
    "            v2.Resize(self.config.params_image_size[:-1]),\n",
    "            v2.ToTensor(),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        if self.config.params_is_agumentation:\n",
    "            train_transform = valid_transform\n",
    "        \n",
    "        dataset = ImageFolder(root=self.config.training_data)\n",
    "\n",
    "        num_train = len(dataset)\n",
    "        indices = list(range(num_train))\n",
    "        split = int(0.2 * num_train)\n",
    "        train_indices, valid_indices = indices[split:], indices[:split]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            sampler=train_sampler,\n",
    "        )\n",
    "        self.valid_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            sampler=valid_sampler,\n",
    "        )\n",
    "        \n",
    "        self.train_loader.dataset.transform = train_transform\n",
    "        self.valid_loader.dataset.transform = valid_transform\n",
    "\n",
    "    @staticmethod\n",
    "    def data_preview(dataset, num_samples=5):\n",
    "\n",
    "        sample_indices = torch_randint(\n",
    "            len(dataset),\n",
    "            (num_samples,),\n",
    "            dtype=torch_int64\n",
    "        )\n",
    "\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "\n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            image, label = dataset[idx]\n",
    "            image = image.permute(1, 2, 0).numpy()\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            image = std * image + mean\n",
    "            image = np.clip(image, 0, 1)\n",
    "\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(f\"Label: {label}\")\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: models):\n",
    "        torch_save(model.state_dict(), path)\n",
    "    \n",
    "    def compile(self):\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.params_learning_rate\n",
    "        )\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        self.model.train()\n",
    "        \n",
    "        train_running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        logger.info(f\"Training start for epoch: {epoch + 1}\")\n",
    "        with tqdm(self.train_loader, unit=\"batch\") as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                inputs, labels = data.to(self.device), target.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_running_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch_max(outputs.data, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                tepoch.set_postfix_str(\n",
    "                    f\"Loss: {loss.item()}, \"\n",
    "                    f\"Running Loss: {train_running_loss / 100:.3f}, \"\n",
    "                    f\"Accuracy: {(train_correct / train_total) * 100:.3f}\"\n",
    "                )\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        \n",
    "        valid_running_loss = 0.0\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "\n",
    "        logger.info(f\"Validation start for epoch: {epoch + 1}\")\n",
    "        with no_grad():\n",
    "            with tqdm(self.valid_loader, unit=\"batch\") as tepoch:\n",
    "                for data, target in tepoch:\n",
    "                    tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                    inputs, labels = data.to(self.device), target.to(self.device)\n",
    "                    outputs = self.model(inputs)\n",
    "                    \n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    \n",
    "                    valid_running_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch_max(outputs.data, 1)\n",
    "                    valid_total += labels.size(0)\n",
    "                    valid_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    tepoch.set_postfix_str(\n",
    "                    f\"Loss: {loss.item()}, \"\n",
    "                    f\"Running Loss: {valid_running_loss / 100:.3f}, \"\n",
    "                    f\"Accuracy: {(valid_correct / valid_total) * 100:.3f}\"\n",
    "                )\n",
    "\n",
    "        logger.info(\n",
    "            f\"[Epoch {epoch + 1}]: \"\n",
    "            f\"Valid Loss: {valid_running_loss / len(self.valid_loader.dataset):.3f}, \"\n",
    "            f\"Valid Accuracy: {(valid_correct / valid_total) * 100:.3f}\"\n",
    "        )\n",
    "\n",
    "    def process(self):\n",
    "        for epoch in range(self.config.params_epochs):\n",
    "            self.train(epoch)\n",
    "            self.validate(epoch)\n",
    "        logger.info(\"Training Completed\")\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_state_dict_path,\n",
    "            model=self.model,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-06 12:01:55,460: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-04-06 12:01:55,461: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-04-06 12:01:55,462: INFO: common: created directory at: artifacts]\n",
      "[2024-04-06 12:01:55,463: INFO: common: created directory at: artifacts/training]\n",
      "[2024-04-06 12:01:56,029: INFO: 2549459238: Training start for epoch: 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Envs\\renal\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████| 623/623 [01:17<00:00,  8.01batch/s, Loss: 1.0451409816741943, Running Loss: 6.677, Accuracy: 68.354]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-06 12:03:13,829: INFO: 2549459238: Validation start for epoch: 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 156/156 [00:19<00:00,  8.04batch/s, Loss: 0.9091838002204895, Running Loss: 1.768, Accuracy: 62.475]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-06 12:03:33,243: INFO: 2549459238: [Epoch 1]: Valid Loss: 0.014, Valid Accuracy: 62.475]\n",
      "[2024-04-06 12:03:33,244: INFO: 2549459238: Training Completed]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    # training.data_preview(training.train_loader.dataset, 10)\n",
    "    training.compile()\n",
    "    training.process()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9959\n"
     ]
    }
   ],
   "source": [
    "print(training.train_generator.num_classes)\n",
    "print(training.train_generator.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\supre\\\\PycharmProjects\\\\RenalHealth-AI'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "print(*a,4,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
